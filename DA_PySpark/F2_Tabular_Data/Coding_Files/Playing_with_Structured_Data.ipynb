{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6033ce12-3c23-4220-8ea9-130b741c7d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "26/01/09 20:36:07 WARN Utils: Your hostname, OnePiece, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "26/01/09 20:36:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/09 20:36:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "26/01/09 20:36:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "### Creating the Session\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\n",
    "    \"EDA of commercial ratio of each channel present in our commericals dataset (structured data)\"\n",
    ").getOrCreate()\n",
    "\n",
    "## Setting the Log level to WARN instead of INFO\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fff93d85-322f-4566-b56b-4da2a4fd49f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_path = \"../../F2_Tabular_Data/Data/BroadcastLogs_2018_Q3_M8_sample.CSV\"\n",
    "\n",
    "logs = spark.read.csv(\n",
    "    path = file_path,\n",
    "    sep = \"|\",\n",
    "    header = True,\n",
    "    inferSchema = True,\n",
    "    timestampFormat = \"yyyy-MM-dd\",\n",
    ")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b27b90ae-e866-4f2e-b909-ed496a541f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- BroadcastLogID: integer (nullable = true)\n",
      " |-- LogServiceID: integer (nullable = true)\n",
      " |-- LogDate: date (nullable = true)\n",
      " |-- SequenceNO: integer (nullable = true)\n",
      " |-- AudienceTargetAgeID: integer (nullable = true)\n",
      " |-- AudienceTargetEthnicID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- ClosedCaptionID: integer (nullable = true)\n",
      " |-- CountryOfOriginID: integer (nullable = true)\n",
      " |-- DubDramaCreditID: integer (nullable = true)\n",
      " |-- EthnicProgramID: integer (nullable = true)\n",
      " |-- ProductionSourceID: integer (nullable = true)\n",
      " |-- ProgramClassID: integer (nullable = true)\n",
      " |-- FilmClassificationID: integer (nullable = true)\n",
      " |-- ExhibitionID: integer (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- EndTime: string (nullable = true)\n",
      " |-- LogEntryDate: date (nullable = true)\n",
      " |-- ProductionNO: string (nullable = true)\n",
      " |-- ProgramTitle: string (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Subtitle: string (nullable = true)\n",
      " |-- NetworkAffiliationID: integer (nullable = true)\n",
      " |-- SpecialAttentionID: integer (nullable = true)\n",
      " |-- BroadcastOriginPointID: integer (nullable = true)\n",
      " |-- CompositionID: integer (nullable = true)\n",
      " |-- Producer1: string (nullable = true)\n",
      " |-- Producer2: string (nullable = true)\n",
      " |-- Language1: integer (nullable = true)\n",
      " |-- Language2: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d72ecdfb-162d-46ce-a9aa-7ddee52aa33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+----------+\n",
      "|BroadcastLogID|LogServiceID|LogDate   |\n",
      "+--------------+------------+----------+\n",
      "|1196192316    |3157        |2018-08-01|\n",
      "|1196192317    |3157        |2018-08-01|\n",
      "|1196192318    |3157        |2018-08-01|\n",
      "|1196192319    |3157        |2018-08-01|\n",
      "|1196192320    |3157        |2018-08-01|\n",
      "+--------------+------------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "### Selecting the columns of our interest\n",
    "\n",
    "logs.select(\"BroadcastLogID\", \"LogServiceID\", \"LogDate\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56d673e2-e90d-49c1-a880-206bec64152a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['BroadcastLogID', 'LogServiceID', 'LogDate'], dtype='<U22'), array(['SequenceNO', 'AudienceTargetAgeID', 'AudienceTargetEthnicID'],\n",
      "      dtype='<U22'), array(['CategoryID', 'ClosedCaptionID', 'CountryOfOriginID'], dtype='<U22'), array(['DubDramaCreditID', 'EthnicProgramID', 'ProductionSourceID'],\n",
      "      dtype='<U22'), array(['ProgramClassID', 'FilmClassificationID', 'ExhibitionID'],\n",
      "      dtype='<U22'), array(['Duration', 'EndTime', 'LogEntryDate'], dtype='<U22'), array(['ProductionNO', 'ProgramTitle', 'StartTime'], dtype='<U22'), array(['Subtitle', 'NetworkAffiliationID', 'SpecialAttentionID'],\n",
      "      dtype='<U22'), array(['BroadcastOriginPointID', 'CompositionID', 'Producer1'],\n",
      "      dtype='<U22'), array(['Producer2', 'Language1', 'Language2'], dtype='<U22')]\n"
     ]
    }
   ],
   "source": [
    "### Peeking at the DF in chunks of 3 cols\n",
    "\n",
    "import numpy as np\n",
    "column_split = np.array_split(\n",
    "    np.array(logs.columns),\n",
    "    len(logs.columns) // 3\n",
    ")\n",
    "\n",
    "print(column_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41fa0348-50f9-40b6-9ce8-9688ebb5d14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "logs = logs.drop(\"BroadcastLogID\", \"SequenceNo\")\n",
    "\n",
    "print(\"BroadcastLogID\" in logs.columns)\n",
    "print(\"SequenceNo\" in logs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b0bedb3-987a-4cce-b7f4-c3babda3d888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Dropping unnecessary columns\n",
    "\n",
    "logs = logs.select(\n",
    "    [x for x in logs.columns if x not in [\"BroadcastLogID\", \"SequenceNO\"]]\n",
    ")\n",
    "\n",
    "logs.drop(*logs.columns) # Unpacking the list and dropping them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97c16b99-b071-4760-89c0-715bc718f7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|        Duration|\n",
      "+----------------+\n",
      "|02:00:00.0000000|\n",
      "|00:00:30.0000000|\n",
      "|00:00:15.0000000|\n",
      "|00:00:15.0000000|\n",
      "|00:00:15.0000000|\n",
      "+----------------+\n",
      "only showing top 5 rows\n",
      "[('Duration', 'string')]\n"
     ]
    }
   ],
   "source": [
    "### Creating new columns\n",
    "from pyspark.sql.functions import col\n",
    "logs.select(col(\"Duration\")).show(5)\n",
    "print(logs.select(col(\"Duration\")).dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a7b2be-5549-403a-8e1d-30f647689194",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extracting hours, minutes and seconds from the Duration col\n",
    "from pyspark.sql.functions as F\n",
    "logs.select(F.col(\"Duration\"),                                                \n",
    "    F.col(\"Duration\").substr(1, 2).cast(\"int\").alias(\"dur_hours\"),    # substr(start_pt, length\n",
    "    F.col(\"Duration\").substr(4, 2).cast(\"int\").alias(\"dur_minutes\"),  \n",
    "    F.col(\"Duration\").substr(7, 2).cast(\"int\").alias(\"dur_seconds\"),  \n",
    ").distinct().show(                                                    \n",
    "    5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c05935-4d56-4348-9344-84d6173a6318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0cd42-b759-4c71-bbb3-b96f2ba3ca6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
